{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d0402e-4ca7-477e-ab9f-d478d0f53a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 0942a285-8ed1-460e-8c96-d8ae74eb9738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Flower server at 10.244.107.149:5555...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n"
     ]
    },
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\r\n -- 10054)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:10.244.107.149:5555 {grpc_message:\"IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\\r\\n -- 10054)\", grpc_status:14}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnecting to Flower server at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserver_address\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAlzheimersClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# convert NumPyClient to Client\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imageclassenv\\lib\\site-packages\\flwr\\compat\\client\\app.py:183\u001b[0m, in \u001b[0;36mstart_client\u001b[1;34m(server_address, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransport type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrpc-bidi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or None (default) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_ENTER)\n\u001b[1;32m--> 183\u001b[0m \u001b[43mstart_client_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_client_app_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_LEAVE)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imageclassenv\\lib\\site-packages\\flwr\\compat\\client\\app.py:394\u001b[0m, in \u001b[0;36mstart_client_internal\u001b[1;34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Receive\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imageclassenv\\lib\\site-packages\\flwr\\compat\\client\\grpc_client\\connection.py:142\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# Receive ServerMessage proto\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# ServerMessage proto --> *Ins --> RecordDict\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     field \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imageclassenv\\lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imageclassenv\\lib\\site-packages\\grpc\\_channel.py:969\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\r\n -- 10054)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:10.244.107.149:5555 {grpc_message:\"IOCP/Socket: Connection reset (An existing connection was forcibly closed by the remote host.\\r\\n -- 10054)\", grpc_status:14}\"\n>"
     ]
    }
   ],
   "source": [
    "# client_Alzheimers.py\n",
    "import flwr as fl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# -----------------------------\n",
    "# CLIENT CONFIG\n",
    "# -----------------------------\n",
    "client_name = \"Alzheimer's\"\n",
    "dataset_path = r\"D:\\DAML\\ML\\datasets neuro\\alzheimers_disease_data.csv\"\n",
    "target_column = \"Diagnosis\"\n",
    "server_address = \"10.244.107.149:5555\"\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD DATA\n",
    "# -----------------------------\n",
    "df = pd.read_csv(dataset_path)\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# PREPROCESSING\n",
    "# -----------------------------\n",
    "numeric_features = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# FLOWER CLIENT\n",
    "# -----------------------------\n",
    "class AlzheimersClient(fl.client.NumPyClient):\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        self.X_train = X_train_processed\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.X_test = X_test_processed\n",
    "        self.y_test = np.array(y_test)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        # Tree-based models: just return empty list to avoid NotFittedError\n",
    "        return []\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        accuracy = self.model.score(self.X_train, self.y_train)\n",
    "        return [], len(self.X_train), {\"accuracy\": float(accuracy), \"client_name\": client_name}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Check if model is fitted before scoring\n",
    "        try:\n",
    "            check_is_fitted(self.model)\n",
    "            accuracy = self.model.score(self.X_test, self.y_test)\n",
    "        except:\n",
    "            accuracy = 0.0  # model not fitted yet\n",
    "        return 0.0, len(self.X_test), {\"accuracy\": float(accuracy), \"client_name\": client_name}\n",
    "\n",
    "# -----------------------------\n",
    "# START CLIENT\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Connecting to Flower server at {server_address}...\")\n",
    "    fl.client.start_client(\n",
    "        server_address=server_address,\n",
    "        client=AlzheimersClient().to_client()  # convert NumPyClient to Client\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593520dc-2e67-42dd-9fb6-f66b099f1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======================== CONFIGURATION ========================\n",
    "FILE_PATH = r\"D:\\ML\\Neurodivergent\\Minsk2020_ALS_dataset.csv\"\n",
    "OUTPUT_DIR = r\"D:\\ML\\Neurodivergent\"\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "N_TRIALS = 100\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# ======================== LOAD DATA ========================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst 5 rows:\\n{df.head()}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "\n",
    "# ======================== IDENTIFY TARGET ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IDENTIFYING TARGET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Try common target column names\n",
    "possible_targets = ['target', 'Target', 'diagnosis', 'Diagnosis', 'class', \n",
    "                   'Class', 'label', 'Label', 'ALS', 'als']\n",
    "\n",
    "target_col = None\n",
    "for col in possible_targets:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print(f\"Target column: '{target_col}'\")\n",
    "print(f\"Target distribution:\\n{df[target_col].value_counts()}\")\n",
    "\n",
    "# ======================== PREPROCESS DATA ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded: {col}\")\n",
    "\n",
    "# Encode target if categorical\n",
    "le_target = None\n",
    "if y.dtype == 'object':\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(y)\n",
    "    print(f\"Target classes: {le_target.classes_}\")\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    print(\"Missing values handled\")\n",
    "\n",
    "# Determine problem type\n",
    "n_classes = len(np.unique(y))\n",
    "is_binary = n_classes == 2\n",
    "print(f\"Problem type: {'Binary' if is_binary else 'Multiclass'} ({n_classes} classes)\")\n",
    "\n",
    "# ======================== SPLIT DATA ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPLITTING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "# ======================== OPTIMIZE HYPERPARAMETERS ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZING HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function\"\"\"\n",
    "    params = {\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': RANDOM_STATE,\n",
    "    }\n",
    "    \n",
    "    if is_binary:\n",
    "        params['objective'] = 'binary:logistic'\n",
    "    else:\n",
    "        params['objective'] = 'multi:softmax'\n",
    "        params['num_class'] = n_classes\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = 'f1_weighted' if n_classes > 2 else 'f1'\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring=scoring, n_jobs=1)\n",
    "    \n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest CV F1 Score: {study.best_trial.value:.4f}\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ======================== TRAIN FINAL MODEL ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING FINAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params['tree_method'] = 'hist'\n",
    "best_params['random_state'] = RANDOM_STATE\n",
    "\n",
    "if is_binary:\n",
    "    best_params['objective'] = 'binary:logistic'\n",
    "else:\n",
    "    best_params['objective'] = 'multi:softmax'\n",
    "    best_params['num_class'] = n_classes\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "# ======================== EVALUATE MODEL ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Get class names\n",
    "target_names = le_target.classes_ if le_target else [f\"Class {i}\" for i in range(n_classes)]\n",
    "\n",
    "# Training metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted' if n_classes > 2 else 'binary')\n",
    "\n",
    "# Test metrics\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted' if n_classes > 2 else 'binary')\n",
    "\n",
    "print(\"\\n--- TRAINING SET ---\")\n",
    "print(f\"Accuracy: {train_acc:.4f}\")\n",
    "print(f\"F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\n--- TEST SET ---\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Classification reports\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TRAINING SET\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
    "\n",
    "# Confusion matrices\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CONFUSION MATRIX - TRAINING SET\")\n",
    "print(\"-\"*70)\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CONFUSION MATRIX - TEST SET\")\n",
    "print(\"-\"*70)\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# ======================== FEATURE IMPORTANCE ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 features:\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# ======================== SAVE RESULTS ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{OUTPUT_DIR}/best_xgboost_als_model.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save encoders\n",
    "encoders_path = f\"{OUTPUT_DIR}/label_encoders_als.pkl\"\n",
    "joblib.dump({\n",
    "    'feature_encoders': label_encoders,\n",
    "    'target_encoder': le_target,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}, encoders_path)\n",
    "print(f\"Encoders saved: {encoders_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "importance_path = f\"{OUTPUT_DIR}/feature_importance_als.csv\"\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "print(f\"Feature importance saved: {importance_path}\")\n",
    "\n",
    "# Save visualizations\n",
    "try:\n",
    "    from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "    \n",
    "    fig1 = plot_optimization_history(study)\n",
    "    fig1.write_html(f\"{OUTPUT_DIR}/optimization_history.html\")\n",
    "    \n",
    "    fig2 = plot_param_importances(study)\n",
    "    fig2.write_html(f\"{OUTPUT_DIR}/param_importances.html\")\n",
    "    \n",
    "    print(\"Visualizations saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save visualizations: {e}\")\n",
    "\n",
    "# ======================== FINAL SUMMARY ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV F1 Score: {study.best_trial.value:.4f}\")\n",
    "print(f\"Test Accuracy:    {test_acc:.4f}\")\n",
    "print(f\"Test F1 Score:    {test_f1:.4f}\")\n",
    "print(f\"Overfitting Gap:  {train_f1 - test_f1:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb121fcb-aa53-4b7a-b11e-18bd4152904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 21:01:14,883] A new study created in memory with name: no-name-78e146ad-d39c-456c-b595-541f4fb9602c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "Dataset loaded: 64 rows, 135 columns\n",
      "\n",
      "First 5 rows:\n",
      "   ID Sex  Age      J1_a      J3_a      J5_a     J55_a      S1_a      S3_a  \\\n",
      "0   8   M   58  0.321817  0.141230  0.199128  0.923634  6.044559  3.196477   \n",
      "1  20   F   57  0.344026  0.177032  0.206458  0.827714  1.967728  0.856639   \n",
      "2  21   F   58  0.264740  0.148228  0.177078  0.532566  1.850893  0.942743   \n",
      "3  22   F   70  0.455793  0.174870  0.243660  0.962641  2.883768  1.284926   \n",
      "4  24   M   66  0.269335  0.143961  0.167465  0.547745  2.327924  1.164109   \n",
      "\n",
      "       S5_a  ...   dCCi(7)   dCCi(8)   dCCi(9)  dCCi(10)  dCCi(11)  dCCi(12)  \\\n",
      "0  3.770575  ... -0.024467 -0.005300  0.051874 -0.037710 -0.026549 -0.021149   \n",
      "1  1.179851  ...  0.002485 -0.004535 -0.000225 -0.006977 -0.012510  0.014773   \n",
      "2  1.071950  ... -0.013927  0.007908  0.007960 -0.009022 -0.012488 -0.015588   \n",
      "3  1.915058  ... -0.019285 -0.021768  0.020495  0.035976 -0.034648  0.008021   \n",
      "4  1.420891  ... -0.005743  0.004726 -0.015247  0.003900 -0.007686 -0.003784   \n",
      "\n",
      "        d_1         F2_i   F2_{conv}  Diagnosis (ALS)  \n",
      "0  4.825476  2526.285657  833.498083                1  \n",
      "1  5.729322  1985.712014  561.802625                1  \n",
      "2  8.258488  2364.695972  796.723440                1  \n",
      "3  5.447137  1860.172768  359.409974                1  \n",
      "4  8.562517  2051.627447  817.111847                1  \n",
      "\n",
      "[5 rows x 135 columns]\n",
      "\n",
      "Missing values:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "======================================================================\n",
      "IDENTIFYING TARGET\n",
      "======================================================================\n",
      "Target column: 'Diagnosis (ALS)'\n",
      "Target distribution:\n",
      "Diagnosis (ALS)\n",
      "0    33\n",
      "1    31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING DATA\n",
      "======================================================================\n",
      "Encoded: Sex\n",
      "Problem type: Binary (2 classes)\n",
      "\n",
      "======================================================================\n",
      "SPLITTING DATA\n",
      "======================================================================\n",
      "Training: 51 samples\n",
      "Test: 13 samples\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZING HYPERPARAMETERS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfd630bd2be4ef595155fe95b454d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 21:01:15,214] Trial 0 finished with value: 0.0 and parameters: {'lambda': 5.6115164153345045, 'alpha': 41.23206532618726, 'max_depth': 4, 'eta': 0.0638792635777333, 'gamma': 2.4041677639819286, 'subsample': 0.5467983561008608, 'colsample_bytree': 0.5174250836504598, 'colsample_bylevel': 0.7598528437324805, 'min_child_weight': 7, 'n_estimators': 77, 'max_leaves': 0}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:15,498] Trial 1 finished with value: 0.0 and parameters: {'lambda': 87.06020878304857, 'alpha': 25.95942550311264, 'max_depth': 2, 'eta': 0.02636424704863906, 'gamma': 2.650640588680904, 'subsample': 0.5912726728878613, 'colsample_bytree': 0.6574269294896714, 'colsample_bylevel': 0.6295835055926348, 'min_child_weight': 5, 'n_estimators': 69, 'max_leaves': 2}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:15,838] Trial 2 finished with value: 0.0 and parameters: {'lambda': 3.839629299804171, 'alpha': 4.192159350410974, 'max_depth': 3, 'eta': 0.08066583652537122, 'gamma': 2.7970640394252375, 'subsample': 0.6542703315240835, 'colsample_bytree': 0.6777243706586128, 'colsample_bylevel': 0.5139351238159994, 'min_child_weight': 7, 'n_estimators': 33, 'max_leaves': 1}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:16,220] Trial 3 finished with value: 0.0 and parameters: {'lambda': 79.02619549708231, 'alpha': 43.70990468130503, 'max_depth': 5, 'eta': 0.037415239225603365, 'gamma': 1.8790490260574548, 'subsample': 0.7052699079536471, 'colsample_bytree': 0.6320457481218804, 'colsample_bylevel': 0.5366114704534336, 'min_child_weight': 6, 'n_estimators': 22, 'max_leaves': 14}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:16,646] Trial 4 finished with value: 0.0 and parameters: {'lambda': 3.2927591344236156, 'alpha': 13.353819088790582, 'max_depth': 3, 'eta': 0.05680612190600298, 'gamma': 5.920392514089517, 'subsample': 0.5554563366576581, 'colsample_bytree': 0.7908753883293675, 'colsample_bylevel': 0.7325398470083344, 'min_child_weight': 10, 'n_estimators': 92, 'max_leaves': 9}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:16,918] Trial 5 finished with value: 0.0 and parameters: {'lambda': 69.78281265126033, 'alpha': 1.4136637008121844, 'max_depth': 2, 'eta': 0.014070456001948426, 'gamma': 3.927972976869379, 'subsample': 0.6166031869068447, 'colsample_bytree': 0.5814047095321688, 'colsample_bylevel': 0.7486212527455789, 'min_child_weight': 5, 'n_estimators': 42, 'max_leaves': 8}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:17,273] Trial 6 finished with value: 0.0 and parameters: {'lambda': 1.9135880487692298, 'alpha': 23.062618121677932, 'max_depth': 2, 'eta': 0.09881982429404657, 'gamma': 7.9502029236699165, 'subsample': 0.5596147044602517, 'colsample_bytree': 0.5016566351370807, 'colsample_bylevel': 0.7446384285364502, 'min_child_weight': 8, 'n_estimators': 79, 'max_leaves': 12}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-10-31 21:01:17,574] Trial 7 finished with value: 0.125 and parameters: {'lambda': 1.4063366777718171, 'alpha': 4.064644058668375, 'max_depth': 2, 'eta': 0.08767930832880343, 'gamma': 6.609683141448022, 'subsample': 0.5992694074557947, 'colsample_bytree': 0.5190675050858071, 'colsample_bylevel': 0.5932946965146987, 'min_child_weight': 5, 'n_estimators': 79, 'max_leaves': 10}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:17,897] Trial 8 finished with value: 0.0 and parameters: {'lambda': 59.48746813219772, 'alpha': 6.342770438858341, 'max_depth': 2, 'eta': 0.07419203085006955, 'gamma': 7.847065437552077, 'subsample': 0.6683831592708489, 'colsample_bytree': 0.7312901539863683, 'colsample_bylevel': 0.6481386789093173, 'min_child_weight': 7, 'n_estimators': 54, 'max_leaves': 0}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:18,217] Trial 9 finished with value: 0.0 and parameters: {'lambda': 1.6435497475111325, 'alpha': 1.1308297976636, 'max_depth': 4, 'eta': 0.038292038296869405, 'gamma': 5.577136220482325, 'subsample': 0.772269942177828, 'colsample_bytree': 0.5747876687446625, 'colsample_bylevel': 0.6231148769106889, 'min_child_weight': 9, 'n_estimators': 38, 'max_leaves': 1}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:18,560] Trial 10 finished with value: 0.125 and parameters: {'lambda': 10.64943860454134, 'alpha': 2.918749825897197, 'max_depth': 3, 'eta': 0.09586211574994233, 'gamma': 9.694792765104523, 'subsample': 0.511617559988355, 'colsample_bytree': 0.5766330376295596, 'colsample_bylevel': 0.5867177778751208, 'min_child_weight': 3, 'n_estimators': 100, 'max_leaves': 4}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:18,887] Trial 11 finished with value: 0.125 and parameters: {'lambda': 17.175482489007376, 'alpha': 3.0595524002528873, 'max_depth': 3, 'eta': 0.0994382823983798, 'gamma': 9.611103599122082, 'subsample': 0.5062470059924186, 'colsample_bytree': 0.5653560751509011, 'colsample_bylevel': 0.5764384593174458, 'min_child_weight': 3, 'n_estimators': 97, 'max_leaves': 5}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:19,214] Trial 12 finished with value: 0.125 and parameters: {'lambda': 14.249492617595335, 'alpha': 2.5342773460149504, 'max_depth': 3, 'eta': 0.08076604658871506, 'gamma': 9.847638926304969, 'subsample': 0.5037423778754186, 'colsample_bytree': 0.5485812647947159, 'colsample_bylevel': 0.5705641151787282, 'min_child_weight': 3, 'n_estimators': 87, 'max_leaves': 5}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:19,554] Trial 13 finished with value: 0.0 and parameters: {'lambda': 8.064618698386276, 'alpha': 9.318862237132224, 'max_depth': 4, 'eta': 0.08847551192808961, 'gamma': 7.852233074870995, 'subsample': 0.6079920273335119, 'colsample_bytree': 0.611977502967705, 'colsample_bylevel': 0.6893253030616895, 'min_child_weight': 4, 'n_estimators': 99, 'max_leaves': 11}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:19,878] Trial 14 finished with value: 0.125 and parameters: {'lambda': 28.062449195582836, 'alpha': 2.060632407806786, 'max_depth': 2, 'eta': 0.06855136608868309, 'gamma': 6.681710922577993, 'subsample': 0.734311593241088, 'colsample_bytree': 0.5344271388435241, 'colsample_bylevel': 0.5821475960237903, 'min_child_weight': 4, 'n_estimators': 67, 'max_leaves': 5}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:20,212] Trial 15 finished with value: 0.0 and parameters: {'lambda': 1.0414090348027398, 'alpha': 6.0390374044032775, 'max_depth': 3, 'eta': 0.08564834725554807, 'gamma': 4.203619697295252, 'subsample': 0.5399893752798308, 'colsample_bytree': 0.6024650284806476, 'colsample_bylevel': 0.6860446723353673, 'min_child_weight': 5, 'n_estimators': 85, 'max_leaves': 10}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:20,507] Trial 16 finished with value: 0.125 and parameters: {'lambda': 23.686574806450274, 'alpha': 3.77643590886165, 'max_depth': 5, 'eta': 0.09121983995781027, 'gamma': 8.827320679256008, 'subsample': 0.587267247227843, 'colsample_bytree': 0.6884738154424251, 'colsample_bylevel': 0.6004782962772914, 'min_child_weight': 4, 'n_estimators': 56, 'max_leaves': 7}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:20,826] Trial 17 finished with value: 0.125 and parameters: {'lambda': 8.795188471333265, 'alpha': 1.8557106334816362, 'max_depth': 2, 'eta': 0.05140336785405273, 'gamma': 6.964809072854718, 'subsample': 0.6294867276871238, 'colsample_bytree': 0.541198448935375, 'colsample_bylevel': 0.7973831588430799, 'min_child_weight': 3, 'n_estimators': 78, 'max_leaves': 15}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:21,144] Trial 18 finished with value: 0.0 and parameters: {'lambda': 4.1966662601927505, 'alpha': 10.629763883900265, 'max_depth': 3, 'eta': 0.09487677486175812, 'gamma': 4.081845154917272, 'subsample': 0.6817653980843922, 'colsample_bytree': 0.5045063634877062, 'colsample_bylevel': 0.5468240379364117, 'min_child_weight': 6, 'n_estimators': 69, 'max_leaves': 7}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:21,546] Trial 19 finished with value: 0.125 and parameters: {'lambda': 35.51865880552076, 'alpha': 4.906113291201443, 'max_depth': 4, 'eta': 0.07626637791897474, 'gamma': 8.873894717873638, 'subsample': 0.5789862076804518, 'colsample_bytree': 0.5996684943623282, 'colsample_bylevel': 0.6761460495742636, 'min_child_weight': 4, 'n_estimators': 89, 'max_leaves': 3}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:21,893] Trial 20 finished with value: 0.125 and parameters: {'lambda': 2.1475671048147804, 'alpha': 2.981588691979563, 'max_depth': 2, 'eta': 0.06299613957171424, 'gamma': 4.989573289938924, 'subsample': 0.7992409485442921, 'colsample_bytree': 0.5555137518777309, 'colsample_bylevel': 0.5086211655808298, 'min_child_weight': 5, 'n_estimators': 100, 'max_leaves': 13}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:22,273] Trial 21 finished with value: 0.125 and parameters: {'lambda': 15.255438297936024, 'alpha': 3.213266301968172, 'max_depth': 3, 'eta': 0.09616041292750485, 'gamma': 9.476648993678344, 'subsample': 0.5068623116315791, 'colsample_bytree': 0.5707355605426412, 'colsample_bylevel': 0.5970872973409859, 'min_child_weight': 3, 'n_estimators': 94, 'max_leaves': 5}. Best is trial 7 with value: 0.125.\n",
      "[I 2025-10-31 21:01:22,639] Trial 22 finished with value: 0.2583333333333333 and parameters: {'lambda': 15.599814426782732, 'alpha': 1.903094061672557, 'max_depth': 3, 'eta': 0.09991925823363836, 'gamma': 8.84167515870973, 'subsample': 0.5243037899534096, 'colsample_bytree': 0.5292031911070872, 'colsample_bylevel': 0.557065662507623, 'min_child_weight': 3, 'n_estimators': 99, 'max_leaves': 4}. Best is trial 22 with value: 0.2583333333333333.\n",
      "[I 2025-10-31 21:01:23,129] Trial 23 finished with value: 0.2583333333333333 and parameters: {'lambda': 10.864431475442217, 'alpha': 1.520498193690769, 'max_depth': 3, 'eta': 0.08755674267803448, 'gamma': 8.598576291210403, 'subsample': 0.5284390134526877, 'colsample_bytree': 0.5252410241387074, 'colsample_bylevel': 0.5379568068113707, 'min_child_weight': 4, 'n_estimators': 83, 'max_leaves': 3}. Best is trial 22 with value: 0.2583333333333333.\n",
      "[I 2025-10-31 21:01:23,459] Trial 24 finished with value: 0.5249999999999999 and parameters: {'lambda': 6.479908712028305, 'alpha': 1.0204067023407153, 'max_depth': 4, 'eta': 0.08644865226354263, 'gamma': 6.819113469248395, 'subsample': 0.5360649864965765, 'colsample_bytree': 0.5158376021266545, 'colsample_bylevel': 0.5457785873837108, 'min_child_weight': 4, 'n_estimators': 85, 'max_leaves': 7}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:23,781] Trial 25 finished with value: 0.5249999999999999 and parameters: {'lambda': 6.3532877826924645, 'alpha': 1.1007050675723773, 'max_depth': 4, 'eta': 0.08309231974212325, 'gamma': 8.36397708606189, 'subsample': 0.5307438325830629, 'colsample_bytree': 0.5380908733063705, 'colsample_bylevel': 0.5396236804198614, 'min_child_weight': 4, 'n_estimators': 85, 'max_leaves': 3}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:24,103] Trial 26 finished with value: 0.2583333333333333 and parameters: {'lambda': 6.176506078058315, 'alpha': 1.019718513162995, 'max_depth': 4, 'eta': 0.07251706041742084, 'gamma': 7.105195507240896, 'subsample': 0.570480241571177, 'colsample_bytree': 0.5437483635739916, 'colsample_bylevel': 0.5477932599746742, 'min_child_weight': 4, 'n_estimators': 64, 'max_leaves': 6}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:24,421] Trial 27 finished with value: 0.125 and parameters: {'lambda': 5.736554885730194, 'alpha': 1.373199459214323, 'max_depth': 5, 'eta': 0.08285029769561764, 'gamma': 8.260563212542337, 'subsample': 0.5302327880758342, 'colsample_bytree': 0.6278255453375474, 'colsample_bylevel': 0.5206249521773043, 'min_child_weight': 6, 'n_estimators': 74, 'max_leaves': 3}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:24,760] Trial 28 finished with value: 0.24500000000000002 and parameters: {'lambda': 3.0214253011384757, 'alpha': 1.8963660519168297, 'max_depth': 4, 'eta': 0.05571802612215682, 'gamma': 7.3379699759944375, 'subsample': 0.6336112244270194, 'colsample_bytree': 0.7166883721480608, 'colsample_bylevel': 0.501637572613194, 'min_child_weight': 3, 'n_estimators': 91, 'max_leaves': 8}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:25,077] Trial 29 finished with value: 0.125 and parameters: {'lambda': 6.9145416812689735, 'alpha': 1.0224554198992013, 'max_depth': 4, 'eta': 0.06612735830943382, 'gamma': 6.260116772119302, 'subsample': 0.5459449684566801, 'colsample_bytree': 0.5002486888084593, 'colsample_bylevel': 0.5610805713708819, 'min_child_weight': 4, 'n_estimators': 74, 'max_leaves': 6}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:25,413] Trial 30 finished with value: 0.0 and parameters: {'lambda': 45.25643943657878, 'alpha': 2.2802828994169593, 'max_depth': 4, 'eta': 0.04576694548066185, 'gamma': 9.027140653865247, 'subsample': 0.5280231149291187, 'colsample_bytree': 0.5255490697513712, 'colsample_bylevel': 0.6206602870488123, 'min_child_weight': 8, 'n_estimators': 82, 'max_leaves': 2}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:25,744] Trial 31 finished with value: 0.3916666666666666 and parameters: {'lambda': 11.412769749119114, 'alpha': 1.3934795940800184, 'max_depth': 4, 'eta': 0.0905436957694741, 'gamma': 8.29490237656312, 'subsample': 0.5233342624114338, 'colsample_bytree': 0.5233075639894628, 'colsample_bylevel': 0.5325836092262256, 'min_child_weight': 4, 'n_estimators': 84, 'max_leaves': 3}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:26,079] Trial 32 finished with value: 0.125 and parameters: {'lambda': 12.010694627246169, 'alpha': 1.5082418950514511, 'max_depth': 5, 'eta': 0.09182969236475765, 'gamma': 7.434918935842585, 'subsample': 0.5625058023830618, 'colsample_bytree': 0.519010676888023, 'colsample_bylevel': 0.5292957323687287, 'min_child_weight': 5, 'n_estimators': 94, 'max_leaves': 4}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:26,401] Trial 33 finished with value: 0.2583333333333333 and parameters: {'lambda': 17.55710314860061, 'alpha': 1.1971404618502648, 'max_depth': 4, 'eta': 0.07783399700794288, 'gamma': 8.297797010501595, 'subsample': 0.5321821682936753, 'colsample_bytree': 0.5521379463848806, 'colsample_bylevel': 0.5538091242568876, 'min_child_weight': 3, 'n_estimators': 87, 'max_leaves': 2}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:26,778] Trial 34 finished with value: 0.125 and parameters: {'lambda': 4.6647349911029155, 'alpha': 1.6957237876389766, 'max_depth': 4, 'eta': 0.08195850235764265, 'gamma': 9.155536832152091, 'subsample': 0.5501839877456504, 'colsample_bytree': 0.5326376889504181, 'colsample_bylevel': 0.5190793207441671, 'min_child_weight': 4, 'n_estimators': 75, 'max_leaves': 0}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:27,236] Trial 35 finished with value: 0.125 and parameters: {'lambda': 21.67987382720968, 'alpha': 1.3078978300551356, 'max_depth': 5, 'eta': 0.0916796980823156, 'gamma': 7.718454336481993, 'subsample': 0.5169372507561415, 'colsample_bytree': 0.5890749261675396, 'colsample_bylevel': 0.5631666924446492, 'min_child_weight': 5, 'n_estimators': 93, 'max_leaves': 4}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:27,663] Trial 36 finished with value: 0.0 and parameters: {'lambda': 7.533709656548084, 'alpha': 1.010773100721447, 'max_depth': 4, 'eta': 0.021662919434902207, 'gamma': 1.3392967394211022, 'subsample': 0.5774542218755456, 'colsample_bytree': 0.6476791686663926, 'colsample_bylevel': 0.5310850252975429, 'min_child_weight': 6, 'n_estimators': 50, 'max_leaves': 1}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:27,971] Trial 37 finished with value: 0.0 and parameters: {'lambda': 2.806601008590961, 'alpha': 32.427378370691756, 'max_depth': 4, 'eta': 0.09992176711430409, 'gamma': 8.408159749468634, 'subsample': 0.5554449451674137, 'colsample_bytree': 0.798290578010425, 'colsample_bylevel': 0.6056084293155412, 'min_child_weight': 4, 'n_estimators': 63, 'max_leaves': 6}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:28,290] Trial 38 finished with value: 0.0 and parameters: {'lambda': 4.722903551602417, 'alpha': 20.042701994054024, 'max_depth': 4, 'eta': 0.06976531563963737, 'gamma': 6.11443735585884, 'subsample': 0.5209493735411459, 'colsample_bytree': 0.5104463427112244, 'colsample_bylevel': 0.6480406010759165, 'min_child_weight': 5, 'n_estimators': 71, 'max_leaves': 3}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:28,548] Trial 39 finished with value: 0.125 and parameters: {'lambda': 12.642201502647065, 'alpha': 2.3096333095253607, 'max_depth': 5, 'eta': 0.06351211470376569, 'gamma': 5.260326689757781, 'subsample': 0.5411021303299998, 'colsample_bytree': 0.7673402711721795, 'colsample_bylevel': 0.5005670011981187, 'min_child_weight': 3, 'n_estimators': 22, 'max_leaves': 2}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:28,868] Trial 40 finished with value: 0.125 and parameters: {'lambda': 9.295504484449708, 'alpha': 1.7486305965080515, 'max_depth': 3, 'eta': 0.0843742008355831, 'gamma': 6.481313514397951, 'subsample': 0.5911928147344164, 'colsample_bytree': 0.5593442067094383, 'colsample_bylevel': 0.5414369602722958, 'min_child_weight': 6, 'n_estimators': 81, 'max_leaves': 9}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:29,206] Trial 41 finished with value: 0.2583333333333333 and parameters: {'lambda': 11.08430386170668, 'alpha': 1.5422974640875216, 'max_depth': 3, 'eta': 0.08862746761654736, 'gamma': 8.49512263100125, 'subsample': 0.5252067063540042, 'colsample_bytree': 0.5217717627762645, 'colsample_bylevel': 0.5273811444623436, 'min_child_weight': 4, 'n_estimators': 83, 'max_leaves': 3}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:29,535] Trial 42 finished with value: 0.5249999999999999 and parameters: {'lambda': 20.463528003984457, 'alpha': 1.2667113268274102, 'max_depth': 3, 'eta': 0.09380315036026873, 'gamma': 9.348499874956621, 'subsample': 0.5004291975955537, 'colsample_bytree': 0.5301179863428757, 'colsample_bylevel': 0.5410951535971417, 'min_child_weight': 4, 'n_estimators': 89, 'max_leaves': 4}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:29,873] Trial 43 finished with value: 0.0 and parameters: {'lambda': 32.890490081296505, 'alpha': 1.2121565576734352, 'max_depth': 3, 'eta': 0.09428976459599218, 'gamma': 9.284381028645292, 'subsample': 0.5013850715671484, 'colsample_bytree': 0.5355179413144164, 'colsample_bylevel': 0.5641988480775704, 'min_child_weight': 10, 'n_estimators': 96, 'max_leaves': 4}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:30,211] Trial 44 finished with value: 0.125 and parameters: {'lambda': 22.985051771107546, 'alpha': 1.20289275114361, 'max_depth': 4, 'eta': 0.0766353725610428, 'gamma': 7.986098654901078, 'subsample': 0.5620708144528687, 'colsample_bytree': 0.5140905778614697, 'colsample_bylevel': 0.5158362026008828, 'min_child_weight': 5, 'n_estimators': 90, 'max_leaves': 1}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:30,569] Trial 45 finished with value: 0.2583333333333333 and parameters: {'lambda': 16.647997354037642, 'alpha': 1.4266431269331854, 'max_depth': 3, 'eta': 0.09986020249636754, 'gamma': 9.875362787973835, 'subsample': 0.5140911056274318, 'colsample_bytree': 0.5842040720710544, 'colsample_bylevel': 0.5781561053556876, 'min_child_weight': 3, 'n_estimators': 86, 'max_leaves': 4}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:30,902] Trial 46 finished with value: 0.5249999999999999 and parameters: {'lambda': 3.4987696675197055, 'alpha': 2.066095971306075, 'max_depth': 3, 'eta': 0.07933751673503799, 'gamma': 7.683276952693205, 'subsample': 0.5393907021598933, 'colsample_bytree': 0.5608715397618499, 'colsample_bylevel': 0.717992329091951, 'min_child_weight': 4, 'n_estimators': 89, 'max_leaves': 6}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:31,217] Trial 47 finished with value: 0.125 and parameters: {'lambda': 3.546621778430031, 'alpha': 2.511719488734065, 'max_depth': 4, 'eta': 0.07938741761074478, 'gamma': 7.486076560961446, 'subsample': 0.5424646417084855, 'colsample_bytree': 0.5648461973233945, 'colsample_bylevel': 0.7750854611147853, 'min_child_weight': 5, 'n_estimators': 79, 'max_leaves': 7}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:31,653] Trial 48 finished with value: 0.125 and parameters: {'lambda': 2.6104248450184655, 'alpha': 1.2312836830964304, 'max_depth': 3, 'eta': 0.08495124317841314, 'gamma': 3.0436322527240556, 'subsample': 0.6054574481075172, 'colsample_bytree': 0.5449521074012338, 'colsample_bylevel': 0.7248813711957989, 'min_child_weight': 4, 'n_estimators': 88, 'max_leaves': 6}. Best is trial 24 with value: 0.5249999999999999.\n",
      "[I 2025-10-31 21:01:31,946] Trial 49 finished with value: 0.0 and parameters: {'lambda': 5.513611875913658, 'alpha': 1.653786731861434, 'max_depth': 4, 'eta': 0.07321516367302325, 'gamma': 7.968573988444906, 'subsample': 0.5014272351025583, 'colsample_bytree': 0.5014576545516566, 'colsample_bylevel': 0.7245140928224331, 'min_child_weight': 7, 'n_estimators': 46, 'max_leaves': 8}. Best is trial 24 with value: 0.5249999999999999.\n",
      "\n",
      "Best CV F1 Score: 0.5250\n",
      "\n",
      "Best hyperparameters:\n",
      "  lambda: 6.479908712028305\n",
      "  alpha: 1.0204067023407153\n",
      "  max_depth: 4\n",
      "  eta: 0.08644865226354263\n",
      "  gamma: 6.819113469248395\n",
      "  subsample: 0.5360649864965765\n",
      "  colsample_bytree: 0.5158376021266545\n",
      "  colsample_bylevel: 0.5457785873837108\n",
      "  min_child_weight: 4\n",
      "  n_estimators: 85\n",
      "  max_leaves: 7\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL\n",
      "======================================================================\n",
      "Model trained successfully with early stopping\n",
      "\n",
      "======================================================================\n",
      "MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "--- TRAINING SET ---\n",
      "Accuracy: 0.4902\n",
      "F1 Score: 0.6579\n",
      "\n",
      "--- TEST SET ---\n",
      "Accuracy: 0.4615\n",
      "F1 Score: 0.6316\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CLASSIFICATION REPORT - TRAINING SET\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00        26\n",
      "     Class 1       0.49      1.00      0.66        25\n",
      "\n",
      "    accuracy                           0.49        51\n",
      "   macro avg       0.25      0.50      0.33        51\n",
      "weighted avg       0.24      0.49      0.32        51\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CLASSIFICATION REPORT - TEST SET\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00         7\n",
      "     Class 1       0.46      1.00      0.63         6\n",
      "\n",
      "    accuracy                           0.46        13\n",
      "   macro avg       0.23      0.50      0.32        13\n",
      "weighted avg       0.21      0.46      0.29        13\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CONFUSION MATRIX - TRAINING SET\n",
      "----------------------------------------------------------------------\n",
      "[[ 0 26]\n",
      " [ 0 25]]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CONFUSION MATRIX - TEST SET\n",
      "----------------------------------------------------------------------\n",
      "[[0 7]\n",
      " [0 6]]\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE\n",
      "======================================================================\n",
      "\n",
      "Top 15 features:\n",
      "   feature  importance\n",
      "        ID         0.0\n",
      "Hi(2)_{mu}         0.0\n",
      "Hi(8)_{sd}         0.0\n",
      "Hi(7)_{sd}         0.0\n",
      "Hi(6)_{sd}         0.0\n",
      "Hi(5)_{sd}         0.0\n",
      "Hi(4)_{sd}         0.0\n",
      "Hi(3)_{sd}         0.0\n",
      "Hi(2)_{sd}         0.0\n",
      "Hi(1)_{sd}         0.0\n",
      "Hi(8)_{mu}         0.0\n",
      "Hi(7)_{mu}         0.0\n",
      "Hi(6)_{mu}         0.0\n",
      "Hi(5)_{mu}         0.0\n",
      "Hi(4)_{mu}         0.0\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "Model saved: D:\\ML\\Neurodivergent/best_xgboost_als_model.pkl\n",
      "Encoders saved: D:\\ML\\Neurodivergent/label_encoders_als.pkl\n",
      "Feature importance saved: D:\\ML\\Neurodivergent/feature_importance_als.csv\n",
      "Visualizations saved\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "Best CV F1 Score: 0.5250\n",
      "Test Accuracy:    0.4615\n",
      "Test F1 Score:    0.6316\n",
      "Overfitting Gap:  0.0263\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======================== CONFIGURATION ========================\n",
    "FILE_PATH = r\"D:\\ML\\Neurodivergent\\Minsk2020_ALS_dataset.csv\"\n",
    "OUTPUT_DIR = r\"D:\\ML\\Neurodivergent\"\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "N_TRIALS = 50\n",
    "CV_FOLDS = 5  # Increased back to 5 for better generalization estimate\n",
    "\n",
    "# ======================== LOAD DATA ========================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst 5 rows:\\n{df.head()}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "\n",
    "# ======================== IDENTIFY TARGET ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IDENTIFYING TARGET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Try common target column names\n",
    "possible_targets = ['target', 'Target', 'diagnosis', 'Diagnosis', 'class', \n",
    "                   'Class', 'label', 'Label', 'ALS', 'als']\n",
    "\n",
    "target_col = None\n",
    "for col in possible_targets:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col is None:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print(f\"Target column: '{target_col}'\")\n",
    "print(f\"Target distribution:\\n{df[target_col].value_counts()}\")\n",
    "\n",
    "# ======================== PREPROCESS DATA ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded: {col}\")\n",
    "\n",
    "# Encode target if categorical\n",
    "le_target = None\n",
    "if y.dtype == 'object':\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(y)\n",
    "    print(f\"Target classes: {le_target.classes_}\")\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    print(\"Missing values handled\")\n",
    "\n",
    "# Determine problem type\n",
    "n_classes = len(np.unique(y))\n",
    "is_binary = n_classes == 2\n",
    "print(f\"Problem type: {'Binary' if is_binary else 'Multiclass'} ({n_classes} classes)\")\n",
    "\n",
    "# ======================== SPLIT DATA ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPLITTING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "# ======================== OPTIMIZE HYPERPARAMETERS ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZING HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function with strong regularization\"\"\"\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'lambda': trial.suggest_float('lambda', 1.0, 100.0, log=True),  # Stronger L2\n",
    "        'alpha': trial.suggest_float('alpha', 1.0, 50.0, log=True),  # Stronger L1\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 5),  # Shallower trees\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.1),  # Lower learning rate\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 10.0),  # Higher min split loss\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.8),  # More aggressive sampling\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 0.8),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),  # Higher min weight\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 100),  # Fewer trees\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 0, 15),  # Limit leaf nodes\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1,\n",
    "        'scale_pos_weight': 1,  # For class imbalance if any\n",
    "    }\n",
    "    \n",
    "    if is_binary:\n",
    "        params['objective'] = 'binary:logistic'\n",
    "    else:\n",
    "        params['objective'] = 'multi:softmax'\n",
    "        params['num_class'] = n_classes\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = 'f1_weighted' if n_classes > 2 else 'f1'\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)  # Prune bad trials\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True, n_jobs=1)\n",
    "\n",
    "print(f\"\\nBest CV F1 Score: {study.best_trial.value:.4f}\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ======================== TRAIN FINAL MODEL ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING FINAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params['tree_method'] = 'hist'\n",
    "best_params['random_state'] = RANDOM_STATE\n",
    "\n",
    "if is_binary:\n",
    "    best_params['objective'] = 'binary:logistic'\n",
    "else:\n",
    "    best_params['objective'] = 'multi:softmax'\n",
    "    best_params['num_class'] = n_classes\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "print(\"Model trained successfully with early stopping\")\n",
    "\n",
    "# ======================== EVALUATE MODEL ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Get class names\n",
    "target_names = le_target.classes_ if le_target else [f\"Class {i}\" for i in range(n_classes)]\n",
    "\n",
    "# Training metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted' if n_classes > 2 else 'binary')\n",
    "\n",
    "# Test metrics\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted' if n_classes > 2 else 'binary')\n",
    "\n",
    "print(\"\\n--- TRAINING SET ---\")\n",
    "print(f\"Accuracy: {train_acc:.4f}\")\n",
    "print(f\"F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "print(\"\\n--- TEST SET ---\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Classification reports\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TRAINING SET\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
    "\n",
    "# Confusion matrices\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CONFUSION MATRIX - TRAINING SET\")\n",
    "print(\"-\"*70)\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"CONFUSION MATRIX - TEST SET\")\n",
    "print(\"-\"*70)\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# ======================== FEATURE IMPORTANCE ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 features:\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# ======================== SAVE RESULTS ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{OUTPUT_DIR}/best_xgboost_als_model.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save encoders\n",
    "encoders_path = f\"{OUTPUT_DIR}/label_encoders_als.pkl\"\n",
    "joblib.dump({\n",
    "    'feature_encoders': label_encoders,\n",
    "    'target_encoder': le_target,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}, encoders_path)\n",
    "print(f\"Encoders saved: {encoders_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "importance_path = f\"{OUTPUT_DIR}/feature_importance_als.csv\"\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "print(f\"Feature importance saved: {importance_path}\")\n",
    "\n",
    "# Save visualizations\n",
    "try:\n",
    "    from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "    \n",
    "    fig1 = plot_optimization_history(study)\n",
    "    fig1.write_html(f\"{OUTPUT_DIR}/optimization_history.html\")\n",
    "    \n",
    "    fig2 = plot_param_importances(study)\n",
    "    fig2.write_html(f\"{OUTPUT_DIR}/param_importances.html\")\n",
    "    \n",
    "    print(\"Visualizations saved\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save visualizations: {e}\")\n",
    "\n",
    "# ======================== FINAL SUMMARY ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best CV F1 Score: {study.best_trial.value:.4f}\")\n",
    "print(f\"Test Accuracy:    {test_acc:.4f}\")\n",
    "print(f\"Test F1 Score:    {test_f1:.4f}\")\n",
    "print(f\"Overfitting Gap:  {train_f1 - test_f1:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1053145b-2bc7-47fb-9cc9-665970eced40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 22:15:39,234] A new study created in memory with name: no-name-67b467ee-1795-45c0-82cc-419846e94c29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (64, 135)\n",
      "Missing values: 0\n",
      "After SMOTE: [26 26]\n",
      "\n",
      "OPTIMIZING HYPERPARAMETERS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cf217b3e504adebac852715810c5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 22:15:40,614] Trial 0 finished with value: 0.755076035076035 and parameters: {'n_estimators': 177, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:42,352] Trial 1 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:44,560] Trial 2 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 271, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:46,135] Trial 3 finished with value: 0.6915406815406815 and parameters: {'n_estimators': 157, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:47,831] Trial 4 finished with value: 0.7546719946719946 and parameters: {'n_estimators': 236, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:49,510] Trial 5 finished with value: 0.736868686868687 and parameters: {'n_estimators': 180, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:51,373] Trial 6 finished with value: 0.755076035076035 and parameters: {'n_estimators': 251, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:52,269] Trial 7 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 110, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:52,795] Trial 8 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 67, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:55,082] Trial 9 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 265, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:55,977] Trial 10 finished with value: 0.755076035076035 and parameters: {'n_estimators': 122, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:57,544] Trial 11 finished with value: 0.755076035076035 and parameters: {'n_estimators': 221, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:15:59,560] Trial 12 finished with value: 0.755076035076035 and parameters: {'n_estimators': 297, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:16:01,132] Trial 13 finished with value: 0.755076035076035 and parameters: {'n_estimators': 219, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:16:02,165] Trial 14 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 139, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:16:02,870] Trial 15 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.755076035076035.\n",
      "[I 2025-10-31 22:16:04,388] Trial 16 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 203, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:05,846] Trial 17 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 197, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:07,115] Trial 18 finished with value: 0.755076035076035 and parameters: {'n_estimators': 199, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:08,225] Trial 19 finished with value: 0.755076035076035 and parameters: {'n_estimators': 150, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:09,641] Trial 20 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 196, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:11,169] Trial 21 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 209, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:12,313] Trial 22 finished with value: 0.755076035076035 and parameters: {'n_estimators': 160, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:13,996] Trial 23 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 236, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:15,399] Trial 24 finished with value: 0.755076035076035 and parameters: {'n_estimators': 188, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:16,649] Trial 25 finished with value: 0.7323487623487624 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:18,634] Trial 26 finished with value: 0.7583333333333334 and parameters: {'n_estimators': 230, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:20,007] Trial 27 finished with value: 0.755076035076035 and parameters: {'n_estimators': 206, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:21,061] Trial 28 finished with value: 0.7113386613386613 and parameters: {'n_estimators': 138, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:22,384] Trial 29 finished with value: 0.755076035076035 and parameters: {'n_estimators': 177, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:24,426] Trial 30 finished with value: 0.755076035076035 and parameters: {'n_estimators': 290, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:26,019] Trial 31 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 210, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:27,487] Trial 32 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 195, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:29,301] Trial 33 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 252, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:31,302] Trial 34 finished with value: 0.6936618936618938 and parameters: {'n_estimators': 214, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:32,750] Trial 35 finished with value: 0.7323487623487624 and parameters: {'n_estimators': 184, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:34,292] Trial 36 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 165, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:36,095] Trial 37 finished with value: 0.7546719946719946 and parameters: {'n_estimators': 245, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:37,918] Trial 38 finished with value: 0.7142679542679543 and parameters: {'n_estimators': 201, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:39,557] Trial 39 finished with value: 0.755076035076035 and parameters: {'n_estimators': 227, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:41,443] Trial 40 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 263, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:43,119] Trial 41 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 241, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:45,023] Trial 42 finished with value: 0.755076035076035 and parameters: {'n_estimators': 279, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:46,922] Trial 43 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 231, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:48,388] Trial 44 finished with value: 0.755076035076035 and parameters: {'n_estimators': 193, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:49,936] Trial 45 finished with value: 0.755076035076035 and parameters: {'n_estimators': 214, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:51,195] Trial 46 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 177, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:53,319] Trial 47 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 256, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:54,815] Trial 48 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 222, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:56,458] Trial 49 finished with value: 0.755076035076035 and parameters: {'n_estimators': 241, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:58,026] Trial 50 finished with value: 0.7323487623487624 and parameters: {'n_estimators': 206, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:16:59,658] Trial 51 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 211, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:17:01,143] Trial 52 finished with value: 0.755076035076035 and parameters: {'n_estimators': 184, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:17:02,657] Trial 53 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 197, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:17:03,889] Trial 54 finished with value: 0.755076035076035 and parameters: {'n_estimators': 151, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:17:05,582] Trial 55 finished with value: 0.7756820956820958 and parameters: {'n_estimators': 222, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 16 with value: 0.7756820956820958.\n",
      "[I 2025-10-31 22:17:07,401] Trial 56 finished with value: 0.7789393939393939 and parameters: {'n_estimators': 235, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 56 with value: 0.7789393939393939.\n",
      "[I 2025-10-31 22:17:09,171] Trial 57 finished with value: 0.7546719946719946 and parameters: {'n_estimators': 233, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 56 with value: 0.7789393939393939.\n",
      "[I 2025-10-31 22:17:10,998] Trial 58 finished with value: 0.7789393939393939 and parameters: {'n_estimators': 262, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 56 with value: 0.7789393939393939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 22:17:13,438] A new study created in memory with name: no-name-aeff0fe5-9364-4529-987a-d5cb202d1e08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 22:17:13,431] Trial 59 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 56 with value: 0.7789393939393939.\n",
      "\n",
      "Best parameters: {'n_estimators': 235, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Best CV F1 Score: 0.7789393939393939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d23d218959b4b4d9ceddc7ffd9d267f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-31 22:17:14,732] Trial 0 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 0 with value: 0.7126012876012877.\n",
      "[I 2025-10-31 22:17:16,870] Trial 1 finished with value: 0.7583333333333334 and parameters: {'n_estimators': 230, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:17,419] Trial 2 finished with value: 0.7287379287379288 and parameters: {'n_estimators': 53, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:19,071] Trial 3 finished with value: 0.755076035076035 and parameters: {'n_estimators': 237, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:20,196] Trial 4 finished with value: 0.7141414141414142 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:21,462] Trial 5 finished with value: 0.755076035076035 and parameters: {'n_estimators': 195, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:23,230] Trial 6 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 221, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:24,032] Trial 7 finished with value: 0.7332073482073482 and parameters: {'n_estimators': 92, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:26,660] Trial 8 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 288, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:27,978] Trial 9 finished with value: 0.7340659340659341 and parameters: {'n_estimators': 184, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:29,826] Trial 10 finished with value: 0.7546719946719946 and parameters: {'n_estimators': 287, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:31,599] Trial 11 finished with value: 0.755076035076035 and parameters: {'n_estimators': 241, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:33,278] Trial 12 finished with value: 0.755076035076035 and parameters: {'n_estimators': 248, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:34,946] Trial 13 finished with value: 0.755076035076035 and parameters: {'n_estimators': 248, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:36,802] Trial 14 finished with value: 0.7583333333333334 and parameters: {'n_estimators': 212, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:38,121] Trial 15 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 137, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:39,979] Trial 16 finished with value: 0.7142679542679543 and parameters: {'n_estimators': 202, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:41,541] Trial 17 finished with value: 0.7517427017427017 and parameters: {'n_estimators': 166, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:43,915] Trial 18 finished with value: 0.7113386613386613 and parameters: {'n_estimators': 269, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:45,484] Trial 19 finished with value: 0.6898740148740149 and parameters: {'n_estimators': 164, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:47,287] Trial 20 finished with value: 0.6936618936618938 and parameters: {'n_estimators': 216, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:48,937] Trial 21 finished with value: 0.755076035076035 and parameters: {'n_estimators': 228, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:50,899] Trial 22 finished with value: 0.755076035076035 and parameters: {'n_estimators': 260, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:52,485] Trial 23 finished with value: 0.755076035076035 and parameters: {'n_estimators': 206, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:54,406] Trial 24 finished with value: 0.7517427017427017 and parameters: {'n_estimators': 228, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:56,529] Trial 25 finished with value: 0.7113386613386613 and parameters: {'n_estimators': 263, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:57,868] Trial 26 finished with value: 0.7323487623487624 and parameters: {'n_estimators': 184, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:17:59,320] Trial 27 finished with value: 0.7126012876012877 and parameters: {'n_estimators': 155, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:18:01,291] Trial 28 finished with value: 0.7323487623487624 and parameters: {'n_estimators': 296, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7583333333333334.\n",
      "[I 2025-10-31 22:18:02,356] Trial 29 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 114, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:03,401] Trial 30 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 113, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:04,375] Trial 31 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:05,323] Trial 32 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:06,322] Trial 33 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:07,380] Trial 34 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:08,141] Trial 35 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:09,304] Trial 36 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 29 with value: 0.7723487623487623.\n",
      "[I 2025-10-31 22:18:09,954] Trial 37 finished with value: 0.7950760350760351 and parameters: {'n_estimators': 63, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:10,518] Trial 38 finished with value: 0.7092174492174491 and parameters: {'n_estimators': 52, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:11,590] Trial 39 finished with value: 0.7525507825507824 and parameters: {'n_estimators': 118, 'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:12,282] Trial 40 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 67, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:13,043] Trial 41 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 82, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:14,041] Trial 42 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 112, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:14,691] Trial 43 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 66, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:15,631] Trial 44 finished with value: 0.7142679542679543 and parameters: {'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:16,968] Trial 45 finished with value: 0.7385353535353536 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:18,182] Trial 46 finished with value: 0.7723487623487623 and parameters: {'n_estimators': 131, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:19,224] Trial 47 finished with value: 0.7142679542679543 and parameters: {'n_estimators': 110, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:19,904] Trial 48 finished with value: 0.7950760350760351 and parameters: {'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "[I 2025-10-31 22:18:20,547] Trial 49 finished with value: 0.7315406815406817 and parameters: {'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 37 with value: 0.7950760350760351.\n",
      "\n",
      "Best parameters found:\n",
      "{'n_estimators': 63, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}\n",
      "Best F1 Score: 0.7950760350760351\n",
      "\n",
      "--- TRAINING SET ---\n",
      "Accuracy: 0.9423076923076923\n",
      "F1 Score: 0.9433962264150944\n",
      "\n",
      "Classification Report (Train):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94        26\n",
      "           1       0.93      0.96      0.94        26\n",
      "\n",
      "    accuracy                           0.94        52\n",
      "   macro avg       0.94      0.94      0.94        52\n",
      "weighted avg       0.94      0.94      0.94        52\n",
      "\n",
      "\n",
      "--- TEST SET ---\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 Score: 0.4444444444444444\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71         7\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.62        13\n",
      "   macro avg       0.63      0.60      0.58        13\n",
      "weighted avg       0.63      0.62      0.59        13\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# ALS RandomForest Optimization with Optuna + SMOTE\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# 1 Load Dataset\n",
    "# =========================\n",
    "data_path = r\"D:\\ML\\Neurodivergent\\Minsk2020_ALS_dataset.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"Missing values:\", data.isnull().sum().sum())\n",
    "\n",
    "# =========================\n",
    "# 2 Data Preprocessing\n",
    "# =========================\n",
    "\n",
    "# Assuming last column is target; adjust if needed\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Handle categorical columns if any\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# =========================\n",
    "# 3 Handle Imbalanced Data with SMOTE\n",
    "# =========================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", np.bincount(y_train_res))\n",
    "\n",
    "# =========================\n",
    "# 4 Define Optuna Objective Function\n",
    "# =========================\n",
    "# =========================\n",
    "# Updated Optuna Objective Function (Regularized)\n",
    "# =========================\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 12)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 4, 12)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 2, 8)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"f1_macro\").mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Run Optuna Study\n",
    "# =========================\n",
    "print(\"\\nOPTIMIZING HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=60, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest parameters:\", study.best_params)\n",
    "print(\"Best CV F1 Score:\", study.best_value)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5 Run Optuna Optimization\n",
    "# =========================\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(study.best_params)\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "\n",
    "# =========================\n",
    "# 6 Train Final Model with Best Parameters\n",
    "# =========================\n",
    "best_params = study.best_params\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "best_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# =========================\n",
    "# 7 Evaluate Model\n",
    "# =========================\n",
    "y_pred_train = best_rf.predict(X_train_res)\n",
    "y_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n--- TRAINING SET ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train_res, y_pred_train))\n",
    "print(\"F1 Score:\", f1_score(y_train_res, y_pred_train))\n",
    "print(\"\\nClassification Report (Train):\\n\", classification_report(y_train_res, y_pred_train))\n",
    "\n",
    "print(\"\\n--- TEST SET ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# =========================\n",
    "# 8 Feature Importance (Optional)\n",
    "# =========================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X.columns).sort_values(ascending=False)[:15]\n",
    "plt.figure(figsize=(8, 5))\n",
    "importances.plot(kind=\"barh\")\n",
    "plt.title(\"Top 15 Feature Importances (Random Forest)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
